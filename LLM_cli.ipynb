{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6dd394dece4af890753803de84e439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import re\n",
    "\n",
    "\n",
    "# Initialize the model and tokenizer\n",
    "model_id = \"/home/random/Documents/textgen/text-generation-webui/models/Phi3_mini_float16\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_key(response):\n",
    "    # Define a regular expression pattern to extract Intent and Entity\n",
    "    pattern = r\"Intent:\\s*(\\w+),\\s*Entity:\\s*(\\w+)\"\n",
    "\n",
    "    # Search for the pattern in the response\n",
    "    match = re.search(pattern, response)\n",
    "\n",
    "    if match:\n",
    "        intent = match.group(1)\n",
    "        entity = match.group(2)\n",
    "        return intent, entity\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intent and entities\n",
    "def extract_intent_and_entities(prompt: str) -> (str):\n",
    "    llm_prompt = (\n",
    "        \"What's the Weather in Seoul?\"\n",
    "    )\n",
    "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "    result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "    response = str(result[0])\n",
    "    \n",
    "\n",
    "\n",
    "    intent, entity = retrieve_key(response)\n",
    "    \n",
    "    return intent, entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "get_weather\n",
      "Seoul\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What's the Weather in Seoul?\"\n",
    "\n",
    "a, b = extract_intent_and_entities(user_prompt)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
